{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Use Cases:\n",
    "\n",
    " * Classifying whole sentences \n",
    " * Classifying each word in a sentence (Named Entity Recognition)\n",
    " * Answering a question given a context\n",
    " * Text summarization\n",
    " * Fill in the blanks\n",
    " * Translating from one language to another  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "import textwrap\n",
    "\n",
    "wrapper = textwrap.TextWrapper(width=80, break_long_words=False, break_on_hyphens=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Whole Sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 629/629 [00:00<00:00, 210kB/s]\n",
      "c:\\Users\\muntanerl2\\Anaconda3\\envs\\NLP-env\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\muntanerl2\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading: 100%|██████████| 268M/268M [00:09<00:00, 29.4MB/s] \n",
      "Downloading: 100%|██████████| 48.0/48.0 [00:00<00:00, 23.9kB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 473kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:\n",
      "This is still one of the best phones in 2023, I would not exchange it for any\n",
      "phone in the world including the 14 Pro Max\n",
      "\n",
      "This sentence is classified with a POSITIVE sentiment\n"
     ]
    }
   ],
   "source": [
    "# Here I have used actual reviews I have found online.\n",
    "# The model needs to determine if the sentiment of the review is positive-\n",
    "# or negative. \n",
    "\n",
    "from cProfile import label\n",
    "\n",
    "\n",
    "sentence = \"This is still one of the best phones in 2023, I would not exchange it for any phone in the world including the 14 Pro Max\"\n",
    "classifier = pipeline('text-classification', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "c = classifier(sentence)\n",
    "\n",
    "print('\\nSentence:')\n",
    "print(wrapper.fill(sentence))\n",
    "print(f\"\\nThis sentence is classified with a {c[0]['label']} sentiment\")\n",
    "\n",
    "# *The below output shows that the sentiment was labeled as positive. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying each Word in a Sentence (Named Entity Recognition):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:\n",
      "Very tidy and lovely AirBnB apartment equipped with everything you need. A good\n",
      "bed and nice bathroom. Greg Towers is a great host and there when you need him,\n",
      "Very nice and wants to share all he know about the area. We had a great stay in\n",
      "London.\n",
      "\n",
      "\n",
      "AirBnB -> ORG\n",
      "Greg Towers -> PER\n",
      "London -> LOC\n"
     ]
    }
   ],
   "source": [
    "# When classifying each word in a sentence, the task is to be able to take words or-\n",
    "# group of wordsand map them to either an organization, a person, or a location.\n",
    "\n",
    "sentence = \"Very tidy and lovely AirBnB apartment equipped with everything you need. A good bed and nice bathroom. Greg Towers is a great host and there when you need him, Very nice and wants to share all he know about the area. We had a great stay in London.\"\n",
    "ner = pipeline('token-classification', model='dbmdz/bert-large-cased-finetuned-conll03-english', grouped_entities=True)\n",
    "ners = ner(sentence)\n",
    "\n",
    "print('\\nSentence:')\n",
    "print(wrapper.fill(sentence))\n",
    "print('\\n')\n",
    "\n",
    "# loops through the words in the sentence and tries to match them to the correct entity.\n",
    "for n in ners:\n",
    "    print(f\"{n['word']} -> {n['entity_group']}\")\n",
    "    \n",
    "# From the output below I can se that the model properly classified-\n",
    "# the entities. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answering a Question given a Context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      " Singapore Airlines was founded in 1947 and was originally known as Malayan\n",
      "Airways. It is the national airline of Singapore and is based at Singapore\n",
      "Changi Airport.  From this hub, the airline flies to more than 60 destinations,\n",
      "with flights to Seoul, Tokyo and Melbourne among the most popular of its routes.\n",
      "It is particularly strong in Southeast Asian and Australian destinations (the\n",
      "so-called Kangaroo Route), but also flies to 6 different continents, covering 35\n",
      "countries. There are more than 100 planes in the Singapore Airlines fleet, most\n",
      "of which are Airbus aircraft plus a smaller amount of Boeings. The company is\n",
      "known for frequently updating the aircraft in its fleet.\n",
      "\n",
      "Question:\n",
      "How many aircrafts does Singapore Airlines have?\n"
     ]
    }
   ],
   "source": [
    "# Here I provide a text as the context and ask a question based on that context-\n",
    "# and see if the model can extract the correct answer from the context.\n",
    "\n",
    "context = '''\n",
    "Singapore Airlines was founded in 1947 and was originally known as Malayan Airways. It is the national airline of Singapore and is based at Singapore Changi Airport. \n",
    "From this hub, the airline flies to more than 60 destinations, with flights to Seoul, Tokyo and Melbourne among the most popular of its routes. \n",
    "It is particularly strong in Southeast Asian and Australian destinations (the so-called Kangaroo Route), but also flies to 6 different continents, covering 35 countries.\n",
    "There are more than 100 planes in the Singapore Airlines fleet, most of which are Airbus aircraft plus a smaller amount of Boeings.\n",
    "The company is known for frequently updating the aircraft in its fleet.'''\n",
    "\n",
    "# Notice that the question that I ask is not how many planes, but how many aircrafts.\n",
    "# This is testing whether the model is able to understand nuaces in the English language.\n",
    "question = 'How many aircrafts does Singapore Airlines have?'\n",
    "\n",
    "print('Text:')\n",
    "print(wrapper.fill(context))\n",
    "print('\\nQuestion:')\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 473/473 [00:00<00:00, 236kB/s]\n",
      "Downloading: 100%|██████████| 261M/261M [00:17<00:00, 14.6MB/s] \n",
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 29.0kB/s]\n",
      "Downloading: 100%|██████████| 213k/213k [00:00<00:00, 433kB/s] \n",
      "Downloading: 100%|██████████| 436k/436k [00:00<00:00, 509kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question:\n",
      "How many aircrafts does Singapore Airlines have?\n",
      "\n",
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'more than 100'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = pipeline('question-answering', model='distilbert-base-cased-distilled-squad')\n",
    "\n",
    "print('\\nQuestion:')\n",
    "print(question + '\\n')\n",
    "print('Answer:')\n",
    "\n",
    "a = qa(context=context, question=question)\n",
    "a['answer']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Summarization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text:\n",
      "\n",
      " Mine is 92 percent after 11 months of use. I have mostly used samsung's 45W\n",
      "charger but sometimes the original 20W from apple.  Never charged overnight and\n",
      "rarely to 100 percent, the battery health is not important and not accurate at\n",
      "all but in my case I know why it is showing 92 percent, because of the fast\n",
      "charging with samsung charger the phone can draw that 27W max charging speed and\n",
      "that must have caused some trouble with the calibration of the battery health.\n",
      "My friend uses 61W apple charger from his MacBook and has 90 percent health\n",
      "after 1 year, so it is normal and does not matter at all, if you know to know\n",
      "the state of your battery you should go and check battery cycle count.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.80k/1.80k [00:00<00:00, 1.79MB/s]\n",
      "Downloading: 100%|██████████| 1.22G/1.22G [00:41<00:00, 29.2MB/s]\n",
      "Downloading: 100%|██████████| 26.0/26.0 [00:00<00:00, 13.0kB/s]\n",
      "Downloading: 100%|██████████| 899k/899k [00:01<00:00, 725kB/s] \n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 853kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarized Text:\n",
      " The battery health is not important and not accurate at all but in my case I\n",
      "know why it is showing 92 percent . Fast charging with samsung charger the phone\n",
      "can draw that 27W max charging speed . My friend uses 61W apple charger from his\n",
      "MacBook and has 90 percent health after 1 year .\n"
     ]
    }
   ],
   "source": [
    "# With text summarization, it does exactly what it says.\n",
    "# The model is able to summarize lenghty sentences into 3 sentences\n",
    "\n",
    "review = '''\n",
    "Mine is 92 percent after 11 months of use. I have mostly used samsung's 45W charger but sometimes the original 20W from apple. \n",
    "Never charged overnight and rarely to 100 percent, the battery health is not important and not accurate at all but in my case I know why it is showing 92 percent, because of the fast charging with samsung charger the phone can draw that 27W max charging speed and that must have caused some trouble with the calibration of the battery health. My friend uses 61W apple charger from his MacBook and has 90 percent health after 1 year, so it is normal and does not matter at all, if you know to know the state of your battery you should go and check battery cycle count.\n",
    "'''\n",
    "\n",
    "print('\\nOriginal Text:\\n')\n",
    "print(wrapper.fill(review))\n",
    "\n",
    "summarize = pipeline('summarization', model='sshleifer/distilbart-cnn-12-6')\n",
    "summarized_text = summarize(review)[0]['summary_text']\n",
    "\n",
    "print('\\nSummarized Text:')\n",
    "print(wrapper.fill(summarized_text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in The Blanks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 480/480 [00:00<00:00, 239kB/s]\n",
      "Downloading: 100%|██████████| 331M/331M [00:21<00:00, 15.6MB/s] \n",
      "Downloading: 100%|██████████| 899k/899k [00:01<00:00, 600kB/s] \n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 634kB/s] \n",
      "Downloading: 100%|██████████| 1.36M/1.36M [00:02<00:00, 519kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is the national anthem of Puerto Rico\n",
      "It is the national capital of Puerto Rico\n",
      "It is the national motto of Puerto Rico\n",
      "It is the national holiday of Puerto Rico\n",
      "It is the national flag of Puerto Rico\n"
     ]
    }
   ],
   "source": [
    "# In this example, if I feed in the sentence, 'It is the national <mask> of Puerto Rico',\n",
    "# the other sentences that are provided are less likely in order of decreasing probability.\n",
    "\n",
    "sentence = 'It is the national <mask> of Puerto Rico'\n",
    "mask = pipeline('fill-mask', model='distilroberta-base')\n",
    "masks = mask(sentence)\n",
    "\n",
    "for m in masks:\n",
    "    print(m['sequence'])\n",
    "\n",
    "# The output shows the most probable to the least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My mother is the most beautiful person in the world\n",
      "My mother is the most famous person in the world\n",
      "My mother is the most amazing person in the world\n",
      "My mother is the most powerful person in the world\n",
      "My mother is the most important person in the world\n"
     ]
    }
   ],
   "source": [
    "sentence = 'My mother is the most <mask> person in the world'\n",
    "mask = pipeline('fill-mask', model='distilroberta-base')\n",
    "masks = mask(sentence)\n",
    "\n",
    "for m in masks:\n",
    "    print(m['sequence'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation (English to Japanese):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muntanerl2\\Anaconda3\\envs\\NLP-env\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "English:\n",
      "My favorite food is steak and fries\n",
      "\n",
      "German:\n",
      "Mein Lieblingsgericht sind Steak und Pommes Frites.\n"
     ]
    }
   ],
   "source": [
    "english = '''My favorite food is steak and fries'''\n",
    "\n",
    "translator = pipeline('translation_en_to_de', model='t5-base')\n",
    "german = translator(english)\n",
    "\n",
    "print('\\nEnglish:')\n",
    "print(english)\n",
    "print('\\nGerman:')\n",
    "print(german[0]['translation_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1bb4f339b974377a4014a725290bb918fe6e27151f1a13a44d796dcfe5250c51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
